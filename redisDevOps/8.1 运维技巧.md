# 运维技巧

- [运维技巧](#运维技巧)
  - [安装](#安装)
  - [启动](#启动)
  - [快捷命令](#快捷命令)
  - [info 命令块](#info-命令块)
    - [server 查看服务信息](#server-查看服务信息)
    - [replication 查看主从信息](#replication-查看主从信息)
    - [sentinel 查看 sentinel 信息](#sentinel-查看-sentinel-信息)
  - [问题记录](#问题记录)
    - [scan 并发量大导致 CPU 占用 100%](#scan-并发量大导致-cpu-占用-100)
    - [sentinel 信息 sentinels 个数异常令人疑惑](#sentinel-信息-sentinels-个数异常令人疑惑)
    - [bgsave 失败导致所有写数据失败](#bgsave-失败导致所有写数据失败)
    - [Openresty 使用连接池](#openresty-使用连接池)
    - [sentinel 模式故障转移时间过长](#sentinel-模式故障转移时间过长)
    - [Next failover delay: I will not start a failover before xxx](#next-failover-delay-i-will-not-start-a-failover-before-xxx)
    - [哨兵启动报错 No such master with specified name](#哨兵启动报错-no-such-master-with-specified-name)
    - [sentinel 启动三台但无法故障转移](#sentinel-启动三台但无法故障转移)

---

## 安装

- 从 https://download.redis.io/releases/ 中下载对应版本
- tar -zxvf xxx.tar.gz 解压
- 进入解压后 src 目录，执行 `make install PREFIX=/usr/local/redis` 指定安装目录

## 启动

redis 的可执行文件就在安装目录下的 src 文件夹中，可以通过 `./src/redis-server redis.conf` 直接启动，sentinel 亦然。

## 快捷命令

```sh
# 命令可以查看当前 redis 在执行什么命令。慎用，内存风暴风险。
redis-cli monitor | tee > /tmp/redis_monitor.log

# 查看 slowlog 条数
redis-cli slowlog len

# 导出 slowlog 最近的 129 条
redis-cli slowlog get 129 > slow-129.log

# 查看配置项，去除注释项和空行
grep -E '^[a-z]' redis.conf | sort

# 根据配置生成连接命令（TODO） 'redis-cli -h 192.168.1.117 -p 26370 -a ORjPtnqVDlrlnkP5KoT5 info sentinel'
```

## info 命令块

> 以下只列除了经常要关注的信息

### server 查看服务信息

```sh
redis_version:5.0.7   # 版本
redis_mode:standalone # 模式（standalone/sentinel/cluster，使用 sentinel 监控的 redis 服务也显示 standalone）
process_id:6668       # pid
tcp_port:6706         # 运行端口
hz:10    # 每秒执行多少次后台任务（后台清理、持久化等），与 redis 延迟性能有关，哨兵/集群中要一致，否则可能不稳定
run_id:8aca34954bb16ccd33efa76f596086a2fc1d359b   # run_id
executable:/home/webuser/redis/6706/redis-server  # 可执行文件位置
config_file:/home/webuser/redis/6706/./redis.conf # 配置文件位置，进而可查看 log 位置
```

### replication 查看主从信息

> 只有 server 实例才有此信息。

```sh
role:slave                    # 当前角色 master / slave
master_host:192.168.1.117     # 谁是 master
master_port:6707              # 谁是 master
master_link_status:up
slave_repl_offset:4448183921  # 同步偏移量
master_repl_offset:4448183921 # master 的偏移量
# master 中应有的信息
role:master                   # 当前角色
connected_slaves:1            # 有多少个 slave 连接
slave0:ip=192.168.1.117,port=6706,state=online,offset=4450546029,lag=0 # slave 信息
```

### sentinel 查看 sentinel 信息

> 只能在 sentinel 上有结果

```sh
sentinel_masters:1  # （应该是）监听了几个 主从
# 谁是 master server，有多少个 slaves，有多少 sentinels 连接
master0:name=mymaster,status=ok,address=192.168.1.117:6707,slaves=1,sentinels=3
```

## 问题记录

### scan 并发量大导致 CPU 占用 100%

命令：`scan INDEX match XXX:* count N`

关键现象：
- 流量偏移到 redis master 节点
- CPU 很高期间慢查询日志有 scan 操作，起止时间与 CPU 飙高时间差不多

原因：业务中有多个 SCAN 命令并发跑，导致流量偏移到 master 并 CPU 飙升。

[参考](https://zhuanlan.zhihu.com/p/381813397)

### sentinel 信息 sentinels 个数异常令人疑惑

在线上某个 sentinel 中执行 `info sentinel` 出现

```sh
10.11.54.187:26372> info sentinel
# Sentinel
sentinel_masters:1
...
master0:name=mymaster,status=sdown,address=10.11.54.187:6704,slaves=2,sentinels=4
```

> 主观下线（Subjectively Down，SDOWN）
> 客观下线（Objectively Down，ODOWN）

这里个信息中有两个异常点：

- `status=sdown` 表明次 sentinel 认为此 mymaster 是下线状态（主观下线）
- `sentinels=4` 表明有四个 sentinel，但实际只有三个，这时因为某 sentinel 配置文件中可能有冗余的 `sentinel known-sentinel` 记录

经查：看到某 sentinel 配置文件中记录有三个 `sentinel known-sentinel` 记录，所以加上自己是 4 个。

总结：sentinel 重启或变更配置之后，一定要注意将 `sentinel known-sentinel` 删除，让它重发现。

又出现异常：等删除 `sentinel known-sentinel` 记录后发现 info 中 `sentinels=4`

经查：原来多个 sentinel 配置文件中的 myid 都一样导致的。

总结：不要拷贝已经运行过的 sentinel.conf 文件，这很不安全。这里应该将 myid 删除，让其自生成。

### bgsave 失败导致所有写数据失败

首先要知道配置 `stop-writes-on-bgsave-error`，配置当 bgsave 失败后是否阻塞写操作，为 `yes` 则在 bgsave 失败时导致写失败。

进一步地，底层还有一个问题会产生令人疑惑的现象：在空闲内存空间足够的情况下 bgsave 仍然失败。

我们在线上有遇到了这样的问题，当时我们发现，redis 占用内存占总机器内存的 60% 左右即发生此问题（未设置实例上限），而根据日志记录，每次 bgsave 只用到几十兆的内存。

从 [redis-faq](https://redis.io/docs/getting-started/faq/) 的 *Background saving fails with a fork() error on Linux?* 一节中可以了解到：

**理论上 bgsave 子进程需要 copy 整个 redis 内存以完成 dump DB，但得益于 Copy-on-Write 机制实际 copy 的内存只有那些需要改动的页。但 Linux 无法提前知道子进程最终到底会占用多少内存，所以在系统配置 overcommit_memory 为 0 时，除非空闲内存真的足够 copy 所有的 redis 的使用内存，否则 fork 将失败。**

解决办法：linux 执行 `echo 1 > /proc/sys/vm/overcommit_memory`。


内核参数 vm.overcommit_memory 详解，参考 [kernel doc](https://www.kernel.org/doc/Documentation/vm/overcommit-accounting)：

> 以下中文解释来自于其他网页的参考。
> 亦可通过 `sysctl vm.overcommit_memory` 查看配置。

可选值 0、1、2。

- 0，表示内核将检查是否有足够内存以供应用进程使用，若不够申请失败
- 1，表示内核允许分配所有物理内存而不管当前内存状态如何
- 2，表示内核允许分配超过所有物理内存和交换内存空间总和的内存

扩展：OOM [参考](https://www.linuxembedded.fr/2020/01/overcommit-memory-in-linux)

当开启 overcommit 后，在内存被用完继续申请时会导致 OOM Killer 杀死其他进程，它有一套选择机制。此时，可用 `vm.overcommit_ratio (percentage)` 或 `'vm.overcommit_kbytes' (absolute value)` 调整用户空间 apps 对内存的使用量。

> What is 'overcommit'?
> In linux, overcommit means the kernel allows more memory to be defined as allocated, which means the allocation adds to the VSZ or virtual set size, than the virtual memory size of the linux system can provide.

### Openresty 使用连接池

我们线上用 [ledgetech/lua-resty-redis-connector](https://github.com/ledgetech/lua-resty-redis-connector) 集成（封装了一层）的 [openresty/lua-resty-redis](https://github.com/openresty/lua-resty-redis)。

使用流程：

```lua
-- 创建一个连接配置
local rc = require("lua.comm.redis.connector").new({
  connection_options = {
    pool_size = 300
  }
})
-- 建立连接
local red, err = rc:connect{ -- lua 语法，调用函数在某些情况下可以不使用括号
  -- some config
}
-- 使用连接
local results, err = red:hvals(key_prefix)
-- 放回连接池    // refer to: https://github.com/openresty/lua-resty-redis#set_keepalive
--              // 调用此函数会立即将 redis 连接转换为 closed 状态，后续任何非 connect() 的操作都会报 closed 的错误。
local ret, err = red:set_keepalive()
```

### sentinel 模式故障转移时间过长

通过 [哨兵-监控](%E5%93%A8%E5%85%B5-1.%E7%9B%91%E6%8E%A7.md) 可知 sentinel 有三个命令来监控主服务的工作状态，在每秒的 PING 失败后 down-after-milliseconds 内没收到响应就会主观下线，主观下线之后一般来说在秒级内就会互相询问判定客观下线。

**down-after-milliseconds 默认是 30s，可以减小此配置来快速发现故障问题缩小故障转移时间**。

### Next failover delay: I will not start a failover before xxx

故障之后 sentinel 可能输出 `Next failover delay: I will not start a failover before Mon Apr 3 06:15:56 2023` 的日志，出现此日志之后 sentinel 在 before 指定的时间点之前不会发生故障转移。

要缩短此日志中的静默时间（默认 6m），可以调整 failover-timeout 配置。

```sh
# sentinel failover-timeout <master-name> <milliseconds>
#
# Specifies the failover timeout in milliseconds. It is used in many ways:
#
# - The time needed to re-start a failover after a previous failover was
#   already tried against the same master by a given Sentinel, is two
#   times the failover timeout.
#
# - The time needed for a slave replicating to a wrong master according
#   to a Sentinel current configuration, to be forced to replicate
#   with the right master, is exactly the failover timeout (counting since
#   the moment a Sentinel detected the misconfiguration).
#
# - The time needed to cancel a failover that is already in progress but
#   did not produced any configuration change (SLAVEOF NO ONE yet not
#   acknowledged by the promoted slave).
#
# - The maximum time a failover in progress waits for all the slaves to be
#   reconfigured as slaves of the new master. However even after this time
#   the slaves will be reconfigured by the Sentinels anyway, but not with
#   the exact parallel-syncs progression as specified.
#
# Default is 3 minutes.
```

此时需要看此配置注释：

- 如果 sentinel 尝试转移到某个机器失败之后重试此机器，是 2 倍的此时间。
- 由于 sentinel 当前配置，从服务跟错了主服务，会切换到正确的主服务，此时是 1 倍的此时间。
- 已经在进程中但没有发生任何配置变动的，需要取消故障转移的时间。
- 新主等待从重新配置跟随新主的最大时长。但过了这个时间从仍然可以重新配置，但不会按 parallel-syncs 配置来了。

测试中发现诸多问题：

- 主/从共三台 redis 同时挂掉，而后同时启动另外两台从，但三个 sentinel 会按 2*failover-timeout 的周期一直输出此日志，经查看，三个 sentinel 一直都选举的是那个挂掉的主。这样就导致了即便启动了两台 redis但仍然无法工作（这时的从应该也没起来）。
- 在测试过程中，还出现过 `READONLY ...` 信息的报错，从日志推测当前的所有连接是应该是到从机的连接，不支持写。

### 哨兵启动报错 No such master with specified name

如果检查配置信息正常，那么这个原因可能配置的顺序问题：

目前要保证先配置好监控 `sentinel monitor mymaster 192.168.1.112 36379 2`，然后再配置用到名字的配置，如 `down-after-milliseconds` 和 `auth-pass`

### sentinel 启动三台但无法故障转移

理论上故障转移经过三个阶段：

- 发现 - 主观下线（sdown）
- 发现 - 客观下线（odown）。
- 选举
- 转移

如果不发生，先确定在哪个阶段出现问题：

- 主观下线（+sdown）后不出现客观下线（+odown）：
  - 检查多个 sentinel 的 myid 是不是有重复的，当非重复数量下降到 quorum 以下会无法进入到客观下线，不要相信 `info sentinel` 中的 `sentinels=xx`，它来源于配置文件的 `known-sentinel`，可能有历史下线的 sentinel 记录。
- 客观下线后开始选举，但有失败：
  - 检查此选举的 id 是在哪里，可能是历史的 `known-sentinel`，但最终选举会持续其他的
  - 若出现 `Next failover delay:` 的时间比较长，参考上文可能需要变更配置
