# 集群

Redis Cluster 是redis 的分布式解决方案。

## 分区方案

- 客户端分区方案，有客户端控制分区，优点逻辑可控，缺点需要自己处理路由、高可用、故障转移
- 代理方案，加代理，优点客户端逻辑简单，缺点加大部署复杂度

## 分区规则

- 节点取余分区。简单，但需要翻倍扩容
- 一致性哈希分区。哈希环，数据倾斜问题
- 虚拟槽分区，16384 个槽，每个节点负责指定量的槽

## 集群功能限制

- key 的批量操作支持性有限。如 mset、mget 不支持映射到不同槽的 key（用 pipeline）
- 事务操作支持有限，若 key 分布在多节点上不支持事务
- key 作为数据分区的最小粒度，不能将 hash、list 等分区存放
- 不支持多数据库空间，只支持 0 号库
- 不支持嵌套树状主从复制结构

## 搭建集群

三步：

- 准备节点。配置项 cluster-enabled: yes
- 加入集群。又叫节点握手。命令：`cluster meet IP PORT`，查看： `cluster nodes`、`cluster info`
- 分配槽或成为从节点。分配槽：`cluster addslots {0...5461}`，成为从节点：`replicate {nodeID}`

## 节点通信流程（Gossip 协议）

协议：基于 P2P 的 Gossip 协议。

工作原理：节点彼此不断进行通信交换信息，一段时候后所有节点就会直到完整集群信息。

流程：

1. 通信两端开启 TCP 通道。（是监听节点的基础端口号上加 10000）
2. 固定周期通过特定规则向**几个**节点发送 ping 消息。（不用知道全部节点，通过通信最终能知道全部节点信息）
3. 接收到 ping 消息时用 pong 消息响应

Gossip 消息四种：

- ping 消息。封装自身节点和部分其他节点的状态数据。
- pong 消息：封装自身状态数据，是 ping 和 meet 的响应消息，也可以是广播消息。
- meet 消息。用于通知新节点加入。
- fail 消息：广播消息，通知某个节点下线的信息。

Gossip 协议优缺点

- 优：天然分布性。
- 缺：频繁信息交换的网络成本和 CPU 成本。

Redis 使用 Gossip 协议（兼顾实时性和成本开销）：

- 固定频率：每 100ms 一次通信
- 节点选择：每秒随机 5 次找出 最久没通信 和 通信时间大于 timeout/2 的节点
- 消息信息：（ping 消息）携带自身信息及 1/10 的其他节点信息

## 扩容集群（增加节点）

三步骤：

- 创建节点。（孤儿节点）
- 加入集群。（`cluster meet <ip port>`）
- 成为从节点或迁移槽。（成为从节点：`cluster replicate {masterNodeID}`，迁移槽见下）

> 特别注意：如果加入集群的节点 A 属于另一个集群，那么会发生集群合并的情况。后果很严重。

槽迁移流程：

1. 目标节点准备导入某个槽。（`cluster setslot {slot} importing {srcNodeID}`）
2. 源节点准备迁出槽数据。（`cluster setslot {slot} migrating {targetNodeID}`）
3. 源节点循环从此槽中获取部分 key。（`cluster getkeysinslot {slot} {count}`）
4. 在源节点执行迁移。（`migrate {targetIP targetPort} "" 0 {timeout} keys {keys...}`）
5. 重复 3~4 直到所有键值迁移完成
6. 通知其他所有主节点槽位已分配（其他节点会）。（`cluster setslot {slot} node {targetNodeID}`）
7. 循环上述步骤，迁移下一个槽位。

> 使用工具可简化操作流程：`redis-trib`

## 收缩集群（删除节点）

步骤：

- 迁移槽（参考上文）
- 向每个节点执行遗忘待下线节点。（`cluster forget {downNodeID}`）

> 建议使用 `redis-trib.rb del-node {host:port} {downNodeID}` 简化操作流程

## 请求路由重定向：访问已经迁移到另一个节点的槽位

场景：节点不记录此槽位或已经迁移到另一个节点，收到对此槽的访问命令。

集群模式下，redis-cli 直连了一个节点，而没用 -c 参数连接整个集群收到命令：

- 计算哈希找到对应槽位。（用 `{hash_tag}`，若无则用全部的 key）
- 根据槽找到对应节点。（Gossip 消息交换获取到每个节点的槽信息，存储在 clusterState.slots[] 中）
- 若节点是自身，直接处理；
- 若节点部署自身，返回 MOVED 重定向错误。（`(error) MOVED 9252 127.0.0.1:6380`）
- (客户端通过 MOVED 信息访问正确的节点)

如上节点对于不属于自己的键命令只回复重定向响应，不负责转发。
redis-cli 在使用 -c 参数后会收到 MOVED 后再次转发请求。

## ASK 重定向：访问正在迁移的槽位

场景：节点正在迁移当前槽（如 4096槽，部分在 A 节点部分在 B 节点），此时此槽收到客户端访问命令。

与 MOVED 区别：
- 返回 MOVED 是节点确认此槽在另一个节点中（可能是刚迁移完，也可能是本来就每分配到这个节点）；
- 返回 ASK 是节点正在迁移此槽，所以此 key 可能在此节点，也可能在另一个节点上。

命令过程：
- 节点收到请求，正在迁移
- 查询键对象是否存在，若存在直接正常返回
- 键不存在，查找槽是否正在迁出，若是则响应 ASK 异常（否则略）。（`(error) ASK {slot} {targetIP:port}`）
- 客户端执行 ASKING 命令。（注意是 `ASKING` 命令，此命令只是打开了一个标识，用于下次命令的携带）
- 客户端发送原命令到 targetIP。（发送时携带了 ASKING 标识，发送完后此标识会被重置）

## 迁移过程中的批量操作

- mget/mset 不可用：slot 在迁移过程中使用 mget、mset 等可能会发生大量错误。
- 可用 pipeline：批量操作后会对应地获得错误信息，然后依据重定向信息进行访问

## 故障转移

### 故障发现

- 主观下线（pfail）：某个节点认为另一个节点不可用。
- 客观下线（fail）：达到阈值的多个节点认为某一个节点不可用

流程：

- 主观下线：集群中每个节点都会定期向其他节点发送 ping 消息，接收节点响应 pong 消息。一旦失败，则认定为**主观下线**。
- 传播消息：当某个节点 A 判定另一个节点 B 为主观下线后，会将 B 节点的状态在集群内传播。
- 接收消息：当 C 节点收到 B 节点下线的消息后，会将信息保存到本地下线报告的链表（`clusterNode.list *fail_reports`）中。
- 验证是否符合客观下线：每个节点收到 pfail 后都会检查是否半数以上都认为时主观下线，不符合则退出。
- 判定为客观下线：当上步验证到半数以上持有槽的主节点都标记 B 为主观下线后判定为客观下线。
- 广播客观下线消息（fail 消息），此消息有两个重要职责：
    - 通知所有节点标记 B 为客观下线**并立即生效**（消息中只包含故障节点 ID）。
    - 通知故障节点的从节点触发**故障转移流程**
- 故障转移流程

点：
- 每个节点都保存了全量的节点信息。
- 只有负责槽的主节点才参与故障发现：从节点只进行对主节点的复制，而且没分配槽的主节点也不参与故障发现。
- 半数以上：为了应对网络分区等原因造成集群分割的情况，被分割的小分区网络好了后也会收到，所以不管。
- 下线状态的维持（误报的处理）：下线报告会一直维持更新，如果有 2*cluster-node-time 内没收到更新则会过期删除。此时间可配置，注意不可以配置的过小，否则可能永远无法标记客观下线而导致故障转移失败。

### 故障恢复

当从节点通过内部定时任务发现自身复制的主节点进入客观下线时，将触发故障恢复流程。

故障恢复流程：

1. 资格检查：每个从节点检查与主节点通信时间大于某阈值则不具备资格，此阈值：`cluster-node-time * cluster-slave-validity-factor`（后者默认 10，即 10 个 cluster-node-time 没联系就没资格了）
2. 准备选举时间：这是延迟触发机制，每个节点判断触发选举时间是按排名通过一定规则生成的，排名越高的越早触发。排名是按复制偏移量计算的。即复制偏移量越大的，排名越靠前，越最早触发选举。
3. 发起选举：更新配置纪元，然后广播选举消息（FAILOVER_AUTH_REQUEST）
4. 选举投票：仍然是只有持有槽的主节点才有资格选举（才会处理上述中的消息），每个节点会对收到的第一个消息进行回复（FAILOVER_AUTH_ACK）作为投票（选举领导者的过程）
5. 替换主节点：当某个从节点有 N/2+1 个选票是可以进行故障恢复。三个步骤：
    - 取消复制变成主节点
    - 向故障主节点撤销负责的槽（clusterDelSlot），并委派给自己（clusterAddSlot）
    - 向集群广播自己的 pong 消息：通知所有节点的“晋级”和掌管的槽信息

点：

- 投票作废：
    - 每个配置纪元代表一次投票周期
    - 依旧是 `cluster-node-timeout * 2` 的时间内没获得足够数量的投票，则本次选举作废，增加纪元开始下一轮
- 为什么没有使用从节点进行选举：
    - 从节点必须大于等于 3 个才能保证 N/2+1，这将导致节点资源浪费，使用持有槽的主节点的话，即便一个从节点也可以做故障恢复。

## 集群读写分离

默认从节点会返回 MOVED 要求重定向访问。

在某个连接中，可以为集群下从节点使用 `readonly` 命令开启只读，但只在当前连接中生效（连接级别）。

## 维护集群

- 集群完整性：默认所有槽位都分配了后集群才可用，否则任何命令都将返回 `(error) CLUSTERDOWN Hash slot not served`。同理故障转移期间集群是不可用的。可以配置 `cluster-require-full-coverage: no` 这样主节点故障时只影响相应节点中的槽。
- 带宽消耗。影响因素主要体现在 **Gossip 协议**、 **读写命令** 和 **节点部署的规模**。
    - Gossip 消息和 `cluster-node-timeout` 相关（超过 2 倍没联系时会直接发送个 ping 联系），所以可以适当调大。
    - 集群尽量均匀分布在更多机器上，避免集中部署。（如在 3 个机器上部署 60 个节点，则带宽消耗非常严重）
    - 在满足业务的情况下尽量避免大集群，或者拆分为多套集群。
- pub/sub 广播问题：订阅发布功能的每条 pub 数据会在所有节点上进行传播，加重带宽负担，需要注意避免使用。（可使用 sentinel 结构专用于发布订阅功能）
- 集群倾斜：即不同节点数据量和请求量出现明显差异，具体分两种 **数据倾斜** 和 **请求倾斜**。
    - 数据倾斜
        - 槽位和节点分配不均：通过 `redis-trib.rb info {host:port}` 定位槽信息和键总量及槽平均键数量。`redis-trib.rb rebalance {host:port}` 可进行平衡处理。
        - 不同槽位数据差异过大。一般发生在 {hash_tag} 离散度差的情况，可通过 `cluster countkeysinslot {slot}` 识别。
        - 集合对象包含大量元素。可通过 `redis-cli --bigkeys` 找到大key
        - 内存相关配置不一致。一般是压缩数据结构配置如 `hash-max-ziplist-value`、`set-max-intset-entries`
    - 请求倾斜
        - 合理设计键：热点大集合对象拆分或使用 hmget 替代 hgetall 避免整个读取
        - 避免使用热键做 hash_key，以致于热数据映射到同一个槽
        - 客户端本地做缓存：减少热键调用