# lk agents

- [开始](#开始)
- [AgentSessin](#agentsessin)
- [Session 状态的存储和传递](#session-状态的存储和传递)
- [Workflows](#workflows)
- [Agent](#agent)
- [Tasks（实验性功能）](#tasks实验性功能)
- [Tool](#tool)
- [Speech \& audio](#speech--audio)
- [Turn Detection 和打断](#turn-detection-和打断)
- [Text 和 Transcriptions](#text-和-transcriptions)
- [Pipeline nodes 和 hooks](#pipeline-nodes-和-hooks)
- [事件和错误处理](#事件和错误处理)

https://docs.livekit.io/agents/build/

LiveKit Agents 项目是基于 livekit SDK 写的一个 Agent 配置编排工具，可以自定义编排出合适的 AgentSession，AgentSession 是 Agent 的主要业务程序。

只有 python 和 nodejs 版本，python 版本需要 ≥3.9。

## 开始

- 需要依赖于：LiveKit Server、AI 提供商（key）
- `python agent.py download-files` 下载插件
- `python agent.py console` 控制台中启动，可以直接说话，配置正确能听到声音
- `python agent.py dev` 控制台中启动

## AgentSessin

AgentSession，核心组件，负责收集用户输入、管理语音管道、调用 LLM 并将输出发给用户。

主要是一些配置项，其结构定义如下

```py
class AgentSession(rtc.EventEmitter[EventTypes], Generic[Userdata_T]):
    def __init__(
        self,
        *,
        turn_detection: NotGivenOr[TurnDetectionMode] = NOT_GIVEN,
        stt: NotGivenOr[stt.STT] = NOT_GIVEN,
        vad: NotGivenOr[vad.VAD] = NOT_GIVEN,
        llm: NotGivenOr[llm.LLM | llm.RealtimeModel] = NOT_GIVEN,
        tts: NotGivenOr[tts.TTS] = NOT_GIVEN,
        mcp_servers: NotGivenOr[list[mcp.MCPServer]] = NOT_GIVEN,
        userdata: NotGivenOr[Userdata_T] = NOT_GIVEN,
        allow_interruptions: bool = True,
        discard_audio_if_uninterruptible: bool = True,
        min_interruption_duration: float = 0.5,
        min_interruption_words: int = 0,
        min_endpointing_delay: float = 0.4,
        max_endpointing_delay: float = 6.0,
        max_tool_steps: int = 3,
        video_sampler: NotGivenOr[_VideoSampler | None] = NOT_GIVEN,
        user_away_timeout: float | None = 15.0,
        agent_false_interruption_timeout: float | None = 4.0,
        min_consecutive_speech_delay: float = 0.0,
        use_tts_aligned_transcript: bool = False,
        preemptive_generation: bool = False,
        conn_options: NotGivenOr[SessionConnectOptions] = NOT_GIVEN,
        loop: asyncio.AbstractEventLoop | None = None,
    ) -> None:
        # ...
```

AgentSession 和 Livekit 的媒体流交互，是通过 RoomIO 处理的，AgentSession 启动的时候会自动创建一个 RoomIO 对象，所有与会的参与者都能够订阅。

自定义 RoomIO 可以手动控制输入和输出，以及控制 Agent 监听或响应哪个参与者。

## Session 状态的存储和传递

- AgentSession 对象中，可以用 `userdata` 存储数据状态，这个属性可以是任意类型（泛型），但推荐使用 `dataclass` 来定义数据结构。
- 初始化 AgentSession 对象的时候需要传入 `userdata` 属性，并在 AgentSession 本身指定其类型（泛型）
- 在 [Tool] 中可以通过 `RunContext.userdata` 使用

> `dataclass` 是 python 内置的一个类装饰器，会为类添加一些默认方法。

## Workflows

任务编排要通过：Agent、Agent 的交接、Task 实现。

- `AgentSession.update_agent()` 可以设置新 Agent
- 从 Tool 调用中返回 Agent 实现切换（LLM 决定合适进行转移）
- Agent 之间用 `userdata` 传递状态数据、`chat_ctx` 传递会话上下文
- Task 创建独立专注的、可重用的任务
- 可以变更 Agent、AgentTask 的属性更新插件（找一个覆盖插件的例子）


## Agent

- `AgentSession.start()` 方法会传入 `Agent` 对象（初始 `Agent`）
- `Agent` 一直控制着会话信息，它包含了自定义提示词、工具和一些逻辑。
- 初始化：继承 `Agent` 类就定义了一个自定义的 Agent；也可以直接实例化一个 `Agent`
- 切换 Agent：`AgentSession.update_agent()` 可以动态变更活动的 `Agent`
- 交接：在 [Tool] 函数返回 `Agent` 可以自动切换 `Agent`（交接、转移控制权）
- 调用任务：它可以调用其他任务，或者将控制权交给另一个 agent。比如如下场景：单个会话中有多种角色、阶段、模式或功能
- [Agent] 和 [Tasks] 默认会开启一个新的对话历史，要包含先前的对话使用 `chat_ctx` 参数
- [Agent] 和 [Tasks] 构造函数中设置的属性可以覆盖先前会话的属性

> 框架中还有 [Tasks] 的概念，这还是实验性的支持，可以临时控制会话完成指定的任务并返回结果。

Agent 对象：

```python
class Agent:
    def __init__(
        self,
        *,
        instructions: str,
        chat_ctx: NotGivenOr[llm.ChatContext | None] = NOT_GIVEN,
        tools: list[llm.FunctionTool | llm.RawFunctionTool] | None = None,
        turn_detection: NotGivenOr[TurnDetectionMode | None] = NOT_GIVEN,
        stt: NotGivenOr[stt.STT | None] = NOT_GIVEN,
        vad: NotGivenOr[vad.VAD | None] = NOT_GIVEN,
        llm: NotGivenOr[llm.LLM | llm.RealtimeModel | None] = NOT_GIVEN,
        tts: NotGivenOr[tts.TTS | None] = NOT_GIVEN,
        mcp_servers: NotGivenOr[list[mcp.MCPServer] | None] = NOT_GIVEN,
        allow_interruptions: NotGivenOr[bool] = NOT_GIVEN,
        min_consecutive_speech_delay: NotGivenOr[float] = NOT_GIVEN,
        use_tts_aligned_transcript: NotGivenOr[bool] = NOT_GIVEN,
    ) -> None:
        # ...
        self._mcp_servers = mcp_servers
        self._activity: AgentActivity | None = None
```

> Agent 和 AgentSession 有相同的属性定义，
> 其使用的优先级核心代码在 livekit..agents.voice.agent_activity.py:2057 行上下。
> Agent 中的定义优先于 AgentSession 中的定义，如果 Agent 中没有给出，会使用 AgentSession 中的定义。

## Tasks（实验性功能）

[Tasks]:https://docs.livekit.io/agents/build/workflows/#tasks

[Tasks] 是一种阻塞式（控制权）完成某项特定功能的工作。

- [Tasks]，任务：专注于特定一件工作，可重用。
- 使用的场景如：通话开始时获取录音的授权；收集特定的结构化数据（地址、手机号等）；一个一个地回答一连串的问题
- Task 在定义后自动执行，所以必须在 AgentSession 中活动状态的上下文中创建，Task 将接管 session 直到获得结果
- [Tasks] 和 [Agent] 在开始时会默认用了一个新的会话历史，要包含先前的会话，使用 `chat_ctx` 参数
- [Tasks] 和 [Agent] 构造函数中设置的属性可以覆盖先前会话的属性

[Agent]:#Agent

定义任务

- 继承 `AgentTask[T]` 类，同时指定返回类型（泛型）
- `on_enter` 方法为执行入口，定义开始任务与用户交互
- 使用 `complete` 方法设置结果

覆盖任何插件：Agent 和 AgentTask 可以通过设置相应的属性覆盖任何插件（如覆盖 tts 变更坐席的声音等）

## Tool

[Tool]: https://docs.livekit.io/agents/build/tools/#return-value

使用场景：LLM 根据客户输入内容自动判定是否要使用注册的工具函数，并从用户输入中收集输入参数、调用工具函数，最终生成响应结果。（Tool 是 LLM 使用的函数）

LiveKit 允许创建**自定义的工具库**来扩展 Agent 的上下文，创建**交互式体验**及克服 LLM 限制。使用 Tool 可以：

- 生成语音：`session.say()` 或 `session.generate_say()`
- 在前端进行**远程过程调用**
- **移交控制权**给其他 Agent
- 在 context 中存储和检索会话信息
- 做任何 python 函数可以做的事情
- 调用外部 API 或查找 RAG 数据

> RAG，Retrieval-Augmented Generation，检索增强生成，是结合了信息检索和生成式 AI 的技术框架。
> 在生成模型生成回答之前，先从外部知识库中检索与问题相关的信息，再让模型基于检索信息进行回答。

使用

- Tool 函数定义可以用 `@function_tool` 装饰器来装饰；
- LLM 可以直接访问类内定义的 Tool；类外定义可以在 Agent 的 `tools` 属性（数组）中引入
- `Agent.update_tools()` 可以更新工具，这是全量更新（可以通过 `agent.tools` 属性引用已创建的实现追加）
- 传入参数：根据名称自动引入
  - 特定的 `context: RunContext` 参数，可以用于访问当前 `session`, `function_call`, `speech_handle` 和 `userdata` 属性
- 返回值
  - 会在发送到 LLM 前自动转换为字符串，LLM 根据返回值生成新的返回或工具调用
  - 返回值为 None 或不填，默认静默地完成 tool 工作，无需 LLM 的回复
  - 返回值中包含 Agent 实例相当于切换 Agent（交接）
- 要动态创建 Tool，可以使用 `function_tool` 函数而不是装饰器，必须提供名称、描述和可调用的函数
- 高级用法：`function_tool` 中的参数 `raw_schema` 可以从 json（静态或动态生成的）获取 tool 的定义


> function_tool 仍然是一种要在服务端定义的的工具函数，即便使用 raw_schema 也是一样，raw_schema 只是将一些约束抽出来了（name、desc、params）。

## Speech & audio

- 预生成语音：Agent 在用户说完话之前就开始生成响应 `AgentSession.preemptive_generation=True`
- 主动初始化语音：`session.say()` 或 `session.generate_reply()`
- 控制 Agent 语音：可以控制 `say()/generate_reply()` 或 `AgentSession.current_speech` 的返回句柄 `SpeechHandle`
  - `SpeechHandle.allow_interruptions(False)` 设置是否允许打断
  - `SpeechHandle.wait_for_playout()` 等待播报完成
  - `SpeechHandle.add_done_callback()` 添加回调
- 打断设置：`AgentSession.allow_interruptions=False`；主动打断 `SpeechHandle.interrupt()`
- 自定义发音：tts_node
- 调整音量：这个实现是获得对应流、帧，重写了帧进行调整的
- 添加背景音：类 `BackgroundAudioPlayer.start(...)`

## Turn Detection 和打断

这里 Turn Detection 是指和用交互的轮次检测，即检测什么时候开始监听用户说话，及什么时候开始响应。

大多数 Turn Detection 是用 VAD 根据用户静音时间做检测的，Agent 用了启发式算法分析轮次的完成。

支持的 Turn Detection 模式：

- Turn Detection 模型，一种基于 VAD 和 STT 自定义的开放权重的模型
- 实时模型：如 OpenAI Realtime API，不配置 `turn_detection` 字段，直接配置 realtime 模型的 trun detection 选项
- VAD only：`trun_detection="vad"`
- STT 端点：使用选择供应商的 STT 返回的短句端点进行判断，如 `turn_detection="stt", vad=silero.VAD.load()`
- 手动控制：完全禁用自动模式，设置 `turn_detection="manual"`  后通过 API 控制 `session.interrupt()`、`session.clear_user_turn()` 和 `session.commit_user_turn()`

## Text 和 Transcriptions

本块介绍了用户在和 Agent 进行交互过程中，文本的格式信息有哪些交互及如何交互。

- 文本语音同步输出
- 通过文本发送 question
- 语音和文本交互的控制

AgentSession 默认启用了转录文本同步的功能：在执行 STT 时，转录的文本实时发布；以及 Agent 进行 TTS 时，音频和文本同步发布。（说到哪个字就输出哪个字）

通过 `AgentSession.start()` 参数中的 `room_output_options.sync_transcription` 控制是否开启，其会通过 `lk.transcription` 的 TextStream 类型的 DataChannel 发布出去的，其中信息中携带 `lk.transcribed_track_id` 表明 TrackID。

AgentSession 中可以监听 `conversation_item_added` 事件，获取输入或输出提交到聊天历史中的信息。

使用 TTS 自己的对齐转录（提供商支持）可以通过 `AgentSession.use_tts_aligned_transcript` 开启，使用此功能有可能丢失原始文本的某些格式。

`Agent.transcription_node()` 方法会在每个词播报前后记录时间信息。

从文本输入中获取用户 question 可以使用 `lk.chat` 的 TextStream 进行交互，如果正在说话中收到消息会触发打断。要禁用文本交互可以设置 `RoomInputOptions.text_enabled` 为 `False`。

如果要禁用语音交互（input/output），可以设置 `AgentSession.room_Xput_options.audio_enabled` 为 `False`，禁用语音交互后，文本响应不会携带 `lk.transcribed_track_id` 属性。

客户端要静音或关闭声音输出，可以使用 注册 RPC 操作 `session.Xput.set_audio_enabled()` 进行开关控制，这种情况不拆媒体流，而只是控制输入和输出内容（无声流）。

AgentSession 主动生成一个问题的响应，可以使用 `AgentSession.generate_reply(user_input="...")` 实现。

## Pipeline nodes 和 hooks

- 在处理路径中可以设置多个节点自定义 Agent 的行为
- 节点是从一个处理过程转到另一个处理过程的点
- 生命周期的 hooks
  - `on_enter()`, 在 Agent 变成活动状态时触发
  - `on_exit()`, 在 Agent 将控制权交接给另一个代理时触发（可用于保存数据、道别、清理工作等）
  - `on_user_turn_completed()`, 在用户的回合完成时触发（Agent 回复前），节点完成后用户消息将加入到上下文中（可用于修改回合内容、取消回复、RAG 等）
    - 入参：`turn_ctx: ChatContext`（上下文）和 `new_message`（用户当前回合的消息）
    - 除了 `new_message`，其他内容要加入历史会话需要用 `update_chat_ctx()` 方法
    - `raise StopResponse()` 可以终止 Agent 生成回复
- STT-LLM-TTS 管道节点
  - `stt_node()`, 将输入音频转录为文本的节点动作（可以增加降噪、自定义语音帧处理、转录文本的后处理、修改转文本策略等等）
  - `llm_node()`, 执行推理并生成新的会话回合或工具调用（可以自定义 LLM 使用方式、LLM 前修改上下文、调整工具调用等）
  - `tts_node()`, 从 LLM 文本输出合成语音（可以自定义 TTS 引擎、添加自定义发音规则等等）
- Realtime 模型节点
  - `realtime_audio_output_node()` 在发给用户前调整输出音频（可以调整输出音量等）
- 转录节点
  - `transcription_node()` 大模型输出文本会经过转录节点（访问转录时间戳，清理格式、修正标点或文本等）

如上的 `x_node()` 函数，定义在 `Agent.default.x_node()` 函数中，可以覆盖、重写此方法。

## 事件和错误处理

AgentSession 在运行过程中，会触发各种事件

- `user_input_transcribed`, 用户说话转录生成结果时触发
- `conversation_item_added`, 一项内容被提交到会话历史时触发
- `function_tools_executed`, 某个 tool 函数执行**完毕**后触发
- `metrics_collected`, 当有新的指标被报告时触发
- `speech_created`, 新的 Agent 开始回复时触发
- `agent_state_changed`, Agent 状态发生变化时触发
- `user_state_changed`, 用户状态变化时触发（由 VAD 驱动）
- `close`, AgentSession 关闭时触发
- 如上的事件，可以使用 `@session.on("user_input_transcribed")` 装饰器，注册处理函数

错误处理

- `error` 事件，和上方事件一样用法，然后可以用
- `FallbackAdapter`：在 STT、LLM、TTS 中有**回退**机制，当某个服务提供商失败时自动切换到次个服务提供商。

```py
session = AgentSession(
    stt=stt.FallbackAdapter(
        [
            assemblyai.STT(),
            deepgram.STT(),
        ]
    ),
    llm=llm.FallbackAdapter(
        [
            openai.LLM(model="gpt-4o"),
            openai.LLM.with_azure(model="gpt-4o", ...),
        ]
    ),
    # ...
```
