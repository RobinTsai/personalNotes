# 优化方法

- 索引
- 表分区（表分区是单点的，所以放在了前面）
- 读写分离
- 分库分表

## 表分区

每个数据库表对应文件系统的一个文件。将请求分摊到不同的表也会增加请求量。

根据数据用多个物理表进行存储，但在逻辑上还是一张表。

好处
- 当查询条件可以判断某个数据位于哪个分区，那么直接在分区中查询，不用扫描整个表。
- 业务代码不用改
- 对分区进行单独管理（备份、恢复）

坏处
- 写可能会慢
- 跨分区查询性能低
- 表连接性能低

参考连接：https://developer.aliyun.com/article/708095
https://www.jianshu.com/p/1cdd3e3c5b3c

### 常见分区方式

Range。按字段区间 0-10、11-20 等。
List。按
哈希。指定属性的哈希函数分区。
Key。按指定属性分区。

注意事项：
- 分区规则根据查询跟则来定。
- 分区条件尽量放在 where 条件中。
- 如果出现跨区查询，适得其反。

## 分库分表

目的（需求）：
- 根据业务进行拆分
- 应对高并发（看读多写少还是写多读少）
- 数据隔离，将核心数据和非核心数据分开

如何拆：
- 不破坏表
- 破坏表。垂直分、水平分
    - 垂直分：一条数据分两段。解决单条数据属性多的问题。
    - 水平分：多条数据分多段。解决数据量多的问题。

额外操作：
- 路由：将原来一条读写请求分散到拆分后的多张表的查询。
- 拼接：将完整数据拼起来。

方法：
- 范围路由：选取有序的列，按一定的范围划分。
    - 难点：分段大小的选择。分段小，增加维护成本；分段大，单表依然存在性能问题。
    - 优点：可以平滑扩充新表，原有的数据不用动
    - 缺点：数据可能分布不均，可能导致部分表性能有问题
- 哈希路由：选取某些列，进行 hash 运算选表。
    - 难点：初始表个数的选择比较难
    - 优点：分布均匀
    - 缺点：扩充新表比较难，数据需要重新分布

问题：
- 分布式 ID 的问题
    - 系统全局唯一：时间戳 + 机器号 + 序列号
    - 高性能：生成 ID 尽量用位运算
    - 高可用：生成 ID 的服务高可用
    - 易于使用好接入：
    - 方式：UUID、独立库的自增、redis 自增、分号段、雪花算法，TinyID、百度的 UIDGenerator、美团的 Leaf。
- 拆分维度的问题
    - 如电商系统中 用户ID、订单ID、商品ID，用哪个字段拆？另外的字段怎么查？
    - 依据自己业务情况进行拆，有所得必有所失
    - 索引表（映射表），用订单ID 和 用户ID 单独拉出来创建出来一个表（也可以放在 redis 中）
- Join 连接查询的问题
    - 在代码层面做 join，而不是在数据库层面做 join
    - 通过 ES 查询，将问题转移
- 事务的问题（分布式事务）
    - shardingsphere
    - XA，jar包，汇总再两阶段提交
- 成本问题
    - 非必要不分库（不过度设计）

## 读写分离

原因：数据库的锁对并发有影响，写锁对读有阻塞行为，读多写少，读的压力会很大，且没必要。

适用场景：读多写少。对写多读少场景没什么优化。


问题：
- 路由问题：通过语句判断适用的库
- 主从同步（一致性）的问题：
    - 如何高效同步：主库开启 binlog，传给从库，从库写入 relaylog，从库解析 relaylog 重现数据。
    - 时间差：
        - 针对于场景需要（如注册后的第一次登录，如用 redis）强制查主库
        - 在特定场景下（如确定是首次注册时）先从后主查


## 实现

分库分表、读写分离

AOP：拦截、判断、分发

- 根据 select 分配到某台机器上（从库）
- 根据 update 分配到某台机器上（主库）
- 根据 where id = x 分配到某台机器上（分库分表）

代码实现：
- 在代码中抽象一层，根据分表规则查询对应库进行访问。（TDDL，Taobao Distributed Data Layer）
- Shardingdbc，需要改代码
- 中间件的封装